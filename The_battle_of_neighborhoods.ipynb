{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.0 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "119bfaff21b32781f6d2764777c04d49502b53816ae403fe48dcf9da50cdb242"
   }
  },
  "interpreter": {
   "hash": "119bfaff21b32781f6d2764777c04d49502b53816ae403fe48dcf9da50cdb242"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# IBM APPLIED DATA SCIENCE CAPSTONE - THE BATTLE OF NEIGHBORHOODS"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## TABLE OF CONTENT\n",
    "+ **THE BUSINESS CASE**\n",
    "+ **THE DATA**\n",
    "+ **THE METHODOLOGY**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## THE BUSINESS CASE \n",
    "My fiance and I love pizza. We eat it minimum once a week and we are pretty picky about it. The best pizza place in our neighbourhood is called [L'Osteria](https://losteria.net/en/). Pizzas are huge, drinks are decent, atmosphere is great and prices are reasonable - perfect place for young people like us!\n",
    "<br>\n",
    "<br>\n",
    "You probably now wonder what this has to do with the Capstone Project for the [IBM - Data Science Professional Certficiate](https://www.coursera.org/professional-certificates/ibm-data-science). L'Osteria is a restaurant chain for italian food, founded in 1999 in Germany. The chain currently has 139 restaurants in Europe, of which the majority is located in Germany. As the chain is looking to expand further, it continuously needs to scout new locations for their next restaurants. As that can be an extremely difficult and long process, this Capstone Project aims to build an analysis tool that recommends neighbourhoods which could be a good fit for new L'Osteria locations. In result, the process of scouting new neihbourhoods should be more time and cost efficient.\n",
    "<br>\n",
    "<br>\n",
    "The tool is going to be based on a k-means clustering algorithm that uses data from Foursquare, Facebook and governmental websites. As my ressources for this project are limited, the tool will be focused on Germany only. However, the approach could be adapted to any other country or region, if enough ressources are provided. Further ressources would also enable adding more socio-economic data which would make the algorithm more precise. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## THE DATA \n",
    "As already mentioned above, we are going to use data from different sources. In this section, I will provide you with a detailed description for each data source used and provide you with the code you need to download/upload the data.\n",
    "<br>\n",
    "<br>\n",
    "### FOURSQUARE DATA\n",
    "[Foursquare](https://foursquare.com/) is an app that lets its users rank all different kinds of venues all over the world. By doing so,Foursquare has build one of the most comprehensive geospatial data sets in the world. The data set covers an extremely large amount of venue and user data that allows you to access everything from a venue's name, location or menu up to user ratings, comments or pictures of each venue. And the best part: Foursquare provides developers an [API](https://developer.foursquare.com/) that is (in limits) free to use! \n",
    "<br>\n",
    "<br>\n",
    "Even though Foursquare provides an incredible variety of data, we will use the venue categories (e.g. sushi restaurant, park, sports club, italian restaurant, etc.) for our analysis only. While it would most likely increase the success of our algorithm to include more information such as rankings or types of user data, we will not include this data due to ressource limitations.\n",
    "<br>\n",
    "<br>\n",
    "To being able to access the Foursquare data during our analysis, you must [sign up](https://developer.foursquare.com/) for a developer account with Foursquare first. Afterwards you need to log into your account and navigate to \"My Apps\". Here, you can create yourself your own client ID and secret. Save these credentials as txt files and name them according to the code below.\n",
    "<br>\n",
    "Once you have created your credentials, you need to create an access token. For that, just follow [this guide](https://developer.foursquare.com/docs/places-api/authentication/) and save the access token in a txt file with the name provided below."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Foursquare credentials loaded.\n"
     ]
    }
   ],
   "source": [
    "# Import working library\n",
    "import pandas as pd\n",
    "\n",
    "# Set credentials\n",
    "client_id = list(pd.read_csv('FOURSQUARE_CLIENT_ID.txt').columns)[0]\n",
    "client_secret = list(pd.read_csv('FOURSQUARE_CLIENT_SECRET.txt').columns)[0]\n",
    "access_token = list(pd.read_csv('FOURSQUARE_ACCESS_TOKEN.txt').columns)[0]\n",
    "\n",
    "# Check out\n",
    "print(\"Foursquare credentials loaded.\")"
   ]
  },
  {
   "source": [
    "You are now set to use the Foursquare API! We will use these credentials at a later point. For now, we continue with our next data source."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### FACEBOOK POPULATION DATA\n",
    "Of all the bad Corona did to us, it also had a good side effect: The big data miners of the world opened up and shared some of their digital gold with the rest of us. So did Facebook by publishing large datasets based on their app usage. You can find a detailed description of their \"Data for Good\" project under this [link](https://dataforgood.fb.com/). Most of the project's data is publicly accessible via [The Humanitarian Data Exchange](https://data.humdata.org/organization/facebook) or [AWS](https://registry.opendata.aws/dataforgood-fb-hrsl/).\n",
    "<br>\n",
    "<br>\n",
    "One of the datasets provided by Facebook contains population density information. According to Facebook, it is the world's most accurate population dataset. It is divided by countries, each containing seven datasets for the distribution of various populations in relation to their respective coordinates: \n",
    "<br>\n",
    "<br>\n",
    "1. Overall population density \n",
    "<br>\n",
    "2. Women\n",
    "<br>\n",
    "3. Men\n",
    "<br> \n",
    "4. Children (ages 0-5) \n",
    "<br>\n",
    "5. Youth (ages 15-24) \n",
    "<br>\n",
    "6. Elderly (ages 60+) \n",
    "<br>\n",
    "7. Women of reproductive age (ages 15-49)\n",
    "<br>\n",
    "<br>\n",
    "Due to limited computing ressources, we will focus on the German datasets for women and men only. You can download them under the following links: \n",
    "<br>\n",
    "<br>\n",
    "1. [DEU_men.csv.zip](https://data.humdata.org/dataset/7d08e2b0-b43b-43fd-a6a6-a308f222cdb2/resource/9b14d65e-ebe1-4509-8680-1f21becc75d9/download/deu_men_2019-08-03_csv.zip)\n",
    "<br>\n",
    "2. [DEU_women.csv.zip](https://data.humdata.org/dataset/7d08e2b0-b43b-43fd-a6a6-a308f222cdb2/resource/26b8ec5b-e40b-40af-a4fc-fcd85bfb0818/download/deu_women_2019-08-03_csv.zip)\n",
    "<br>\n",
    "<br>\n",
    "Once downloaded, we can execute the code below. It will load the data, transform and standardize it. Furthermore, we are merging the two datasets to receive one comprehensive population dataset. Finally, we will add a total population column to our dataset which is the sum of all male and female population. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(32433580, 5)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    LATITUDE  LONGITUDE  MALE_POPULATION  FEMALE_POPULATION  TOTAL_POPULATION\n",
       "0  48.814306   8.459306         1.451906           1.552587          3.004493\n",
       "1  48.815694   8.480972         1.451906           1.552587          3.004493\n",
       "2  48.804861   8.445139         1.451906           1.552587          3.004493\n",
       "3  48.787361   8.449306         1.451906           1.552587          3.004493\n",
       "4  48.819028   8.464306         1.451906           1.552587          3.004493\n",
       "5  48.824583   8.415139         1.451906           1.552587          3.004493\n",
       "6  48.775417   8.455972         1.451906           1.552587          3.004493\n",
       "7  48.817639   8.482917         1.451906           1.552587          3.004493\n",
       "8  48.769306   8.432917         1.451906           1.552587          3.004493\n",
       "9  48.817361   8.485417         1.451906           1.552587          3.004493"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>LATITUDE</th>\n      <th>LONGITUDE</th>\n      <th>MALE_POPULATION</th>\n      <th>FEMALE_POPULATION</th>\n      <th>TOTAL_POPULATION</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>48.814306</td>\n      <td>8.459306</td>\n      <td>1.451906</td>\n      <td>1.552587</td>\n      <td>3.004493</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>48.815694</td>\n      <td>8.480972</td>\n      <td>1.451906</td>\n      <td>1.552587</td>\n      <td>3.004493</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>48.804861</td>\n      <td>8.445139</td>\n      <td>1.451906</td>\n      <td>1.552587</td>\n      <td>3.004493</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>48.787361</td>\n      <td>8.449306</td>\n      <td>1.451906</td>\n      <td>1.552587</td>\n      <td>3.004493</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>48.819028</td>\n      <td>8.464306</td>\n      <td>1.451906</td>\n      <td>1.552587</td>\n      <td>3.004493</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>48.824583</td>\n      <td>8.415139</td>\n      <td>1.451906</td>\n      <td>1.552587</td>\n      <td>3.004493</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>48.775417</td>\n      <td>8.455972</td>\n      <td>1.451906</td>\n      <td>1.552587</td>\n      <td>3.004493</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>48.817639</td>\n      <td>8.482917</td>\n      <td>1.451906</td>\n      <td>1.552587</td>\n      <td>3.004493</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>48.769306</td>\n      <td>8.432917</td>\n      <td>1.451906</td>\n      <td>1.552587</td>\n      <td>3.004493</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>48.817361</td>\n      <td>8.485417</td>\n      <td>1.451906</td>\n      <td>1.552587</td>\n      <td>3.004493</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "# Load density data\n",
    "male_population = pd.read_csv('DEU_men_2019-08-03.csv')\n",
    "female_population = pd.read_csv('DEU_women_2019-08-03.csv')\n",
    "\n",
    "# Standardize columns\n",
    "male_population.rename(columns={\"latitude\":\"LATITUDE\", \"longitude\":\"LONGITUDE\", \"population\":\"MALE_POPULATION\"}, inplace=True)\n",
    "female_population.rename(columns={\"latitude\":\"LATITUDE\", \"longitude\":\"LONGITUDE\", \"population\":\"FEMALE_POPULATION\"}, inplace=True)\n",
    "\n",
    "# Merge on geolocation\n",
    "population = male_population.merge(female_population, how='outer', on=['LATITUDE', 'LONGITUDE'])\n",
    "\n",
    "# Calculate total population column\n",
    "population['TOTAL_POPULATION'] = population['MALE_POPULATION'] + population['FEMALE_POPULATION']\n",
    "\n",
    "# Visualize\n",
    "print(population.shape)\n",
    "population.head(10)"
   ]
  },
  {
   "source": [
    "### GERMAN BORDER DATA\n",
    "As our Facebook data compromises over 32 million unique geospatial data points that are randomized, there is no way for us to filter this data according to cities or neighborhoods in Germany. One solution to this problem would be to reverse engineer the coordinates with libraries like geopy. However, the accessible APIs via geopy only allow a limited number of calls per day. For +32 million datapoints it would require month do download all necessary data this way. Of course there is always the option to upgrade to a paid enterprise plan to speed up this process. However, this would require financial ressources that I currently do not have. \n",
    "<br>\n",
    "<br>\n",
    "Luckily, there is another option! The German government publishes shape files of all municipalities Germany. You might ask yourself now how that is going to help us in regards to neighborhoods. The shapefiles provide us with unique polygons for each municipality that we can use to filter our Facebook data. Once filtered, the amount of coordinates that need to be reverse engineered is going to be much less time and cost intensive.\n",
    "<br>\n",
    "<br>\n",
    "The shape files can be downloaded on this [website](https://gdz.bkg.bund.de/index.php/default/digitale-geodaten/verwaltungsgebiete.html) for free. For this excercise, I have used the [vg250_12-31.utm32s.shape.ebenen](https://daten.gdz.bkg.bund.de/produkte/vg/vg250_ebenen_1231/aktuell/vg250_12-31.utm32s.shape.ebenen.zip) dataset. Once you click the link it will direct you to download the respective zip file. Alternatively, you can access the needed files on the Github repository. \n",
    "<br>\n",
    "<br>\n",
    "The following code will allow you to load the shape file and convert it into a pandas data frame:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(11139, 27)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   ADE  GF  BSG           ARS       AGS       SDV_ARS          GEN    BEZ  \\\n",
       "0    6   4    1  010010000000  01001000  010010000000    Flensburg  Stadt   \n",
       "1    6   4    1  010020000000  01002000  010020000000         Kiel  Stadt   \n",
       "2    6   4    1  010030000000  01003000  010030000000       Lübeck  Stadt   \n",
       "3    6   4    1  010040000000  01004000  010040000000   Neumünster  Stadt   \n",
       "4    6   4    1  010510011011  01051011  010510011011  Brunsbüttel  Stadt   \n",
       "\n",
       "   IBZ        BEM  ... FK_S3   NUTS         ARS_0     AGS_0         WSK  \\\n",
       "0   60  kreisfrei  ...     R  DEF01  010010000000  01001000  2008-01-01   \n",
       "1   60  kreisfrei  ...     R  DEF02  010020000000  01002000  2006-01-01   \n",
       "2   60  kreisfrei  ...     R  DEF03  010030000000  01003000  2006-02-01   \n",
       "3   60  kreisfrei  ...     R  DEF04  010040000000  01004000  1970-04-26   \n",
       "4   61         --  ...     R  DEF05  010510011011  01051011  2009-01-01   \n",
       "\n",
       "           DEBKG_ID            RS        SDV_RS          RS_0  \\\n",
       "0  DEBKGDL20000E5MA  010010000000  010010000000  010010000000   \n",
       "1  DEBKGDL20000004J  010020000000  010020000000  010020000000   \n",
       "2  DEBKGDL20000DYMA  010030000000  010030000000  010030000000   \n",
       "3  DEBKGDL20000E4SA  010040000000  010040000000  010040000000   \n",
       "4  DEBKGDL20000E2IK  010510011011  010510011011  010510011011   \n",
       "\n",
       "                                              coords  \n",
       "0  [(526513.7529476011, 6075133.41194521), (52654...  \n",
       "1  [(575841.569459631, 6032148.031753651), (57586...  \n",
       "2  [(623056.1506336611, 5983746.445214357), (6231...  \n",
       "3  [(565015.6516448742, 6000637.513467715), (5651...  \n",
       "4  [(510789.9284805175, 5977425.101718364), (5109...  \n",
       "\n",
       "[5 rows x 27 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ADE</th>\n      <th>GF</th>\n      <th>BSG</th>\n      <th>ARS</th>\n      <th>AGS</th>\n      <th>SDV_ARS</th>\n      <th>GEN</th>\n      <th>BEZ</th>\n      <th>IBZ</th>\n      <th>BEM</th>\n      <th>...</th>\n      <th>FK_S3</th>\n      <th>NUTS</th>\n      <th>ARS_0</th>\n      <th>AGS_0</th>\n      <th>WSK</th>\n      <th>DEBKG_ID</th>\n      <th>RS</th>\n      <th>SDV_RS</th>\n      <th>RS_0</th>\n      <th>coords</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6</td>\n      <td>4</td>\n      <td>1</td>\n      <td>010010000000</td>\n      <td>01001000</td>\n      <td>010010000000</td>\n      <td>Flensburg</td>\n      <td>Stadt</td>\n      <td>60</td>\n      <td>kreisfrei</td>\n      <td>...</td>\n      <td>R</td>\n      <td>DEF01</td>\n      <td>010010000000</td>\n      <td>01001000</td>\n      <td>2008-01-01</td>\n      <td>DEBKGDL20000E5MA</td>\n      <td>010010000000</td>\n      <td>010010000000</td>\n      <td>010010000000</td>\n      <td>[(526513.7529476011, 6075133.41194521), (52654...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>6</td>\n      <td>4</td>\n      <td>1</td>\n      <td>010020000000</td>\n      <td>01002000</td>\n      <td>010020000000</td>\n      <td>Kiel</td>\n      <td>Stadt</td>\n      <td>60</td>\n      <td>kreisfrei</td>\n      <td>...</td>\n      <td>R</td>\n      <td>DEF02</td>\n      <td>010020000000</td>\n      <td>01002000</td>\n      <td>2006-01-01</td>\n      <td>DEBKGDL20000004J</td>\n      <td>010020000000</td>\n      <td>010020000000</td>\n      <td>010020000000</td>\n      <td>[(575841.569459631, 6032148.031753651), (57586...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6</td>\n      <td>4</td>\n      <td>1</td>\n      <td>010030000000</td>\n      <td>01003000</td>\n      <td>010030000000</td>\n      <td>Lübeck</td>\n      <td>Stadt</td>\n      <td>60</td>\n      <td>kreisfrei</td>\n      <td>...</td>\n      <td>R</td>\n      <td>DEF03</td>\n      <td>010030000000</td>\n      <td>01003000</td>\n      <td>2006-02-01</td>\n      <td>DEBKGDL20000DYMA</td>\n      <td>010030000000</td>\n      <td>010030000000</td>\n      <td>010030000000</td>\n      <td>[(623056.1506336611, 5983746.445214357), (6231...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>4</td>\n      <td>1</td>\n      <td>010040000000</td>\n      <td>01004000</td>\n      <td>010040000000</td>\n      <td>Neumünster</td>\n      <td>Stadt</td>\n      <td>60</td>\n      <td>kreisfrei</td>\n      <td>...</td>\n      <td>R</td>\n      <td>DEF04</td>\n      <td>010040000000</td>\n      <td>01004000</td>\n      <td>1970-04-26</td>\n      <td>DEBKGDL20000E4SA</td>\n      <td>010040000000</td>\n      <td>010040000000</td>\n      <td>010040000000</td>\n      <td>[(565015.6516448742, 6000637.513467715), (5651...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6</td>\n      <td>4</td>\n      <td>1</td>\n      <td>010510011011</td>\n      <td>01051011</td>\n      <td>010510011011</td>\n      <td>Brunsbüttel</td>\n      <td>Stadt</td>\n      <td>61</td>\n      <td>--</td>\n      <td>...</td>\n      <td>R</td>\n      <td>DEF05</td>\n      <td>010510011011</td>\n      <td>01051011</td>\n      <td>2009-01-01</td>\n      <td>DEBKGDL20000E2IK</td>\n      <td>010510011011</td>\n      <td>010510011011</td>\n      <td>010510011011</td>\n      <td>[(510789.9284805175, 5977425.101718364), (5109...</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 27 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "# Import working libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Define function to read shape files\n",
    "def read_shapefile(shp_path):\n",
    "\t\"\"\"\n",
    "\tRead a shapefile into a Pandas dataframe with a 'coords' column holding\n",
    "\tthe geometry information. This uses the pyshp package.\n",
    "\t\"\"\"\n",
    "    # Import working libraries\n",
    "\timport shapefile\n",
    "\n",
    "\t# Read file, parse out the records and shapes\n",
    "\tsf = shapefile.Reader(shp_path)\n",
    "\tfields = [x[0] for x in sf.fields][1:]\n",
    "\trecords = sf.records()\n",
    "\tshps = [s.points for s in sf.shapes()]\n",
    "\n",
    "\t# Write into a dataframe\n",
    "\tdf = pd.DataFrame(columns=fields, data=records)\n",
    "\tdf = df.assign(coords=shps)\n",
    "\n",
    "    # Check out\n",
    "\treturn df\n",
    "\n",
    "# Set path\n",
    "path = r\"C:\\Users\\maurice.buettgenbach\\OneDrive - Aquila Capital Management GmbH\\Desktop\\Desktop\\Private\\IBM\\10_Capstone project\\IBM_The_battle_of_neighborhoods\\VG250_GEM.shp\"\n",
    "\n",
    "# Run function\n",
    "municipalities = read_shapefile(path)\n",
    "\n",
    "#Visualize\n",
    "print(municipalities.shape)\n",
    "municipalities.head()"
   ]
  },
  {
   "source": [
    "As we can see, the dataframe covers a lot of information that we don't need. So let us drop these columns and have a closer look on the columns that matter:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           GEN    BEZ                                             coords\n",
       "0    Flensburg  Stadt  [(526513.7529476011, 6075133.41194521), (52654...\n",
       "1         Kiel  Stadt  [(575841.569459631, 6032148.031753651), (57586...\n",
       "2       Lübeck  Stadt  [(623056.1506336611, 5983746.445214357), (6231...\n",
       "3   Neumünster  Stadt  [(565015.6516448742, 6000637.513467715), (5651...\n",
       "4  Brunsbüttel  Stadt  [(510789.9284805175, 5977425.101718364), (5109..."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>GEN</th>\n      <th>BEZ</th>\n      <th>coords</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Flensburg</td>\n      <td>Stadt</td>\n      <td>[(526513.7529476011, 6075133.41194521), (52654...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Kiel</td>\n      <td>Stadt</td>\n      <td>[(575841.569459631, 6032148.031753651), (57586...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Lübeck</td>\n      <td>Stadt</td>\n      <td>[(623056.1506336611, 5983746.445214357), (6231...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Neumünster</td>\n      <td>Stadt</td>\n      <td>[(565015.6516448742, 6000637.513467715), (5651...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Brunsbüttel</td>\n      <td>Stadt</td>\n      <td>[(510789.9284805175, 5977425.101718364), (5109...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# Kick out unnecessary columns\n",
    "municipalities = municipalities[[\n",
    "\t\"GEN\",\n",
    "\t\"BEZ\",\n",
    "\t\"coords\"\n",
    "]]\n",
    "\n",
    "# Visualize\n",
    "municipalities.head()"
   ]
  },
  {
   "source": [
    "Much better! So what are we looking at? The column \"GEN\" shows the respective municipality and colume \"BEZ\" its type (e.g. \"Stadt\" which is German for \"City\").\n",
    "<br>\n",
    "<br>\n",
    "The column \"coords\" contains the border information in form of a polygon. Having a closer look at the data, we can see that the coordinates are not in standard WGS84 (GPS) format. A quick research shows that the German authorities (for whatever reason) still work with the ETRS89 format. Since the libraries we will use in later steps all work with WGS84, we need to convert the coords column first. \n",
    "<br>\n",
    "<br>\n",
    "Luckily, we can use the [Pyproj](https://pyproj4.github.io/pyproj/stable/index.html) library for this. Pyproj is a complex library that allows you to convert coordinates from (nearly) every kind of system to another. To use the library correctly, one needs to know the so called \"[EPSG code](https://en.wikipedia.org/wiki/EPSG_Geodetic_Parameter_Dataset)\" for the respective coordinate system. In our case, ETRS89 has the code \"25832\" and WGS84 has \"44326\". The following code will now convert the coordinates to GPS standard:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 11139/11139 [00:24<00:00, 451.74it/s]\n",
      "\n",
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           GEN    BEZ                                             coords\n",
       "0    Flensburg  Stadt  [(54.82264090832692, 9.412664108896106), (54.8...\n",
       "1         Kiel  Stadt  [(54.43137670797368, 10.169158185796851), (54....\n",
       "2       Lübeck  Stadt  [(53.98736518615582, 10.876835000180577), (53....\n",
       "3   Neumünster  Stadt  [(54.14971926107453, 9.995446122384308), (54.1...\n",
       "4  Brunsbüttel  Stadt  [(53.94509189359393, 9.164391038995467), (53.9..."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>GEN</th>\n      <th>BEZ</th>\n      <th>coords</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Flensburg</td>\n      <td>Stadt</td>\n      <td>[(54.82264090832692, 9.412664108896106), (54.8...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Kiel</td>\n      <td>Stadt</td>\n      <td>[(54.43137670797368, 10.169158185796851), (54....</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Lübeck</td>\n      <td>Stadt</td>\n      <td>[(53.98736518615582, 10.876835000180577), (53....</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Neumünster</td>\n      <td>Stadt</td>\n      <td>[(54.14971926107453, 9.995446122384308), (54.1...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Brunsbüttel</td>\n      <td>Stadt</td>\n      <td>[(53.94509189359393, 9.164391038995467), (53.9...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# Import workin library\n",
    "from tqdm import tqdm # Progress visualization\n",
    "from pyproj import Transformer # Coordinate transformation\n",
    "\n",
    "# Define coordinate systems\n",
    "system_in = \"EPSG:25832\" # ETRS89\n",
    "system_out = \"EPSG:4326\" # WGS84\n",
    "\n",
    "# Define transformer\n",
    "transformer = Transformer.from_crs(system_in, system_out)\n",
    "\n",
    "# Loop through each entry in dataset\n",
    "for i in tqdm(range(len(municipalities.index))):\n",
    "    # Loop through each coordinate pair in polygon\n",
    "    for index, tuple in enumerate(municipalities['coords'][i]):\n",
    "        # Get coordinates in ETRS89 format\n",
    "        lat_in = tuple[0] \n",
    "        lng_in = tuple[1]\n",
    "        # Execute transformer\n",
    "        transformed_coordinates = transformer.transform(lat_in, lng_in)\n",
    "        # Parse transformed coordinates back to dataset\n",
    "        municipalities['coords'][i][index] = transformed_coordinates\n",
    "\n",
    "# Spacer\n",
    "print()\n",
    "print()\n",
    "\n",
    "# Visualize\n",
    "municipalities.head()"
   ]
  },
  {
   "source": [
    "### OPEN STREET MAP\n",
    "To reverse geocode our filtered coordinates, we will use the publicly available geospatial data by [OpenStreetMap](https://wiki.openstreetmap.org/wiki/Main_Page). OpenStreetMap is a non profit organization that collects geospatial data and makes in available to the public. We will use this data to reverse geocode our filtered coordinates. We can do so by using the service [Nominatim](https://wiki.openstreetmap.org/wiki/Nominatim) via the [GeoPy](https://geopy.readthedocs.io/en/stable/) library. More details to this in the library section. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### L'OSTERIA DATA\n",
    "Finally, we will use the geospatial data from the L'Osteria website to localize their existing restaurants. As the chain is rather big and it would take too long to extract the coordinates from the website by hand, we will use the [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) library to scrape the address data from the website. We then can use Nominatim to receive their coordinates at a later stage.\n",
    "<br>\n",
    "<br>\n",
    "Usually, once would use BeautifulSoup to scrape data directly from a website. However, in this case, the website has an event button that hides most of the restaurants. We could use another library called [Selenium](https://www.selenium.dev/) to click the button for us automatically - but that would be pretty much overkill as we can also click on it 10 times manually and save it in our working directory. Since this is not an ongoing analysis but a one time thing, an automation definitely makes no sense. \n",
    "<br>\n",
    "<br>\n",
    "The following code scrapes the data we need from the downloaded html file (available in the repository) and transforms it so that we can use it later:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 121/121 [00:00<00:00, 446.04it/s]\n",
      "\n",
      "df shape: (121, 3)\n",
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                     STREET ZIP_CODE      CITY\n",
       "0      Gut-Daemme-Strasse 1    52070    Aachen\n",
       "1       Franziskanergasse 5    92224    Amberg\n",
       "2  Pearl-S.-Buck-Strasse 12    86156  Augsburg\n",
       "3  Albert-Schenavsky-Str. 2    86165  Augsburg\n",
       "4      Maximilianstrasse 83    95444  Bayreuth\n",
       "5     Hilda-Geiringer-Weg 4    10557    Berlin\n",
       "6          Alt Mahlsdorf 88    12623    Berlin\n",
       "7          Memhardstrasse 3    10178    Berlin\n",
       "8   Mildred-Harnack-Str. 11    10243    Berlin\n",
       "9            Savignyplatz 5    10623    Berlin"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>STREET</th>\n      <th>ZIP_CODE</th>\n      <th>CITY</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Gut-Daemme-Strasse 1</td>\n      <td>52070</td>\n      <td>Aachen</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Franziskanergasse 5</td>\n      <td>92224</td>\n      <td>Amberg</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Pearl-S.-Buck-Strasse 12</td>\n      <td>86156</td>\n      <td>Augsburg</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Albert-Schenavsky-Str. 2</td>\n      <td>86165</td>\n      <td>Augsburg</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Maximilianstrasse 83</td>\n      <td>95444</td>\n      <td>Bayreuth</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Hilda-Geiringer-Weg 4</td>\n      <td>10557</td>\n      <td>Berlin</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Alt Mahlsdorf 88</td>\n      <td>12623</td>\n      <td>Berlin</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Memhardstrasse 3</td>\n      <td>10178</td>\n      <td>Berlin</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Mildred-Harnack-Str. 11</td>\n      <td>10243</td>\n      <td>Berlin</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Savignyplatz 5</td>\n      <td>10623</td>\n      <td>Berlin</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# Import working libraries\n",
    "import requests # Request handling\n",
    "from bs4 import BeautifulSoup # HTML search\n",
    "import re # String handling\n",
    "import ast # String handling\n",
    "\n",
    "# Open document and transform to BS object\n",
    "with open(\"Restaurants - L'Osteria.htm\") as page:\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "\n",
    "# Define results\n",
    "results = soup.find(id='losteria-restaurants-list-wrapper')\n",
    "\n",
    "# Find elements\n",
    "page_elements = results.find_all('div', class_='address')\n",
    "\n",
    "# Create variable to store data in\n",
    "restaurants = pd.DataFrame()\n",
    "\n",
    "# Iterate through found elements\n",
    "for page_element in tqdm(page_elements):\n",
    "    # Isolate address\n",
    "    element = str(page_element)\n",
    "    # Get rid of unnecessary characters\n",
    "    element = element.replace(\"\\n\", \"\")\n",
    "    element = element.replace(\"\\r\", \"\")\n",
    "    # Get rid of spaces\n",
    "    element = element.replace(\" \", \"\")\n",
    "    # Search for address in between <div>\n",
    "    search_result = re.search(\">(.*)<\", element)\n",
    "    # Store search result in new variable\n",
    "    address = search_result.group(1)\n",
    "    # Get street\n",
    "    street = address.split(\",\")[0]\n",
    "    # Add space between street name and house number\n",
    "    street = re.sub(r\"([0-9]+(\\.[0-9]+)?)\",r\" \\1 \", street).strip()\n",
    "    # Add space before Capital letter\n",
    "    street = re.sub(r\"(?<=\\w)([A-Z])\", r\" \\1\", street).strip()\n",
    "    # Get ZIP code and city\n",
    "    address = address.split(\",\")[1]\n",
    "    # Isolate ZIP code\n",
    "    zip_code = re.split('(\\d+)', address)[1]\n",
    "    # Isolate city\n",
    "    city = re.split('(\\d+)', address)[2]\n",
    "    # Create temporary df\n",
    "    temp_df = pd.DataFrame()\n",
    "    # Add data to df\n",
    "    temp_df['STREET'] = [street]\n",
    "    temp_df['ZIP_CODE'] = zip_code\n",
    "    temp_df['CITY'] = city\n",
    "    # Append to variable\n",
    "    restaurants = restaurants.append(temp_df)\n",
    "# Reset index\n",
    "restaurants.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Replace cryptic html for German characters\n",
    "restaurants = restaurants.replace('Ã¤', \"ae\", regex=True) # For \"ä\"\n",
    "restaurants = restaurants.replace('Ã¼', \"ue\", regex=True) # For \"ü\"\n",
    "restaurants = restaurants.replace('Ã¶', \"oe\", regex=True) # For \"ö\"\n",
    "restaurants = restaurants.replace('ÃŸ', \"ss\", regex=True) # For \"ß\"\n",
    "\n",
    "# Add spacer for output\n",
    "print()\n",
    "print()\n",
    "\n",
    "# Visualize variable\n",
    "print(\"df shape:\", restaurants.shape)\n",
    "restaurants.head(10)"
   ]
  },
  {
   "source": [
    "## THE METHODOLOGY\n",
    "Alright! We have our base datasets ready. In this section, we will explore our data, apply further standardization/transformation where needed and finally use some machine learning techniques. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### ANALYZING L'OSTERIA LOCATIONS\n",
    "Let us begin with our L'Osteria data. We have successfully scraped the locations of each restaurant shown on their website. As we are going to limit our analysis to Germany, we will need to check whether all of these addresses actually lie within Germany. And what is the easiest way to do that? Right, let's look on a map!\n",
    "<br>\n",
    "<br>\n",
    "But before we can do that, we unfortunately need to get the coordinates for each address. We can do so by using the service of Nominatim that we can access via the [Geopy](https://geopy.readthedocs.io/en/stable/) library. The following code takes our existing addresses and fetches their coordinates from the Nominatim API:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 121/121 [01:00<00:00,  2.00it/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                     STREET ZIP_CODE      CITY   LATITUDE  LONGITUDE\n",
       "0      Gut-Daemme-Strasse 1    52070    Aachen  50.797335   6.107450\n",
       "1       Franziskanergasse 5    92224    Amberg  49.446234  11.855468\n",
       "2  Pearl-S.-Buck-Strasse 12    86156  Augsburg  48.371837  10.865182\n",
       "3  Albert-Schenavsky-Str. 2    86165  Augsburg  48.381857  10.931547\n",
       "4      Maximilianstrasse 83    95444  Bayreuth  49.944196  11.571159"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>STREET</th>\n      <th>ZIP_CODE</th>\n      <th>CITY</th>\n      <th>LATITUDE</th>\n      <th>LONGITUDE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Gut-Daemme-Strasse 1</td>\n      <td>52070</td>\n      <td>Aachen</td>\n      <td>50.797335</td>\n      <td>6.107450</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Franziskanergasse 5</td>\n      <td>92224</td>\n      <td>Amberg</td>\n      <td>49.446234</td>\n      <td>11.855468</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Pearl-S.-Buck-Strasse 12</td>\n      <td>86156</td>\n      <td>Augsburg</td>\n      <td>48.371837</td>\n      <td>10.865182</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Albert-Schenavsky-Str. 2</td>\n      <td>86165</td>\n      <td>Augsburg</td>\n      <td>48.381857</td>\n      <td>10.931547</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Maximilianstrasse 83</td>\n      <td>95444</td>\n      <td>Bayreuth</td>\n      <td>49.944196</td>\n      <td>11.571159</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# Import working library\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "# Create new variable\n",
    "lats = []\n",
    "longs = []\n",
    "\n",
    "# Set geolocator and set user agent\n",
    "geolocator = Nominatim(user_agent=\"german_italian_restaurant_analysis\")\n",
    "\n",
    "# Get temporary df\n",
    "temp_df = restaurants.copy()\n",
    "\n",
    "# Loop through df and get addresses for coordinates\n",
    "for i in tqdm(range(len(temp_df))):\n",
    "    # Get address\n",
    "    address = temp_df.iloc[i, 0:1].values[0]\n",
    "    # Get ZIP code\n",
    "    zip_code = temp_df.iloc[i, 1:2].values[0]\n",
    "    # Get city\n",
    "    city = temp_df.iloc[i, 2:3].values[0]\n",
    "    # Define full address\n",
    "    full_address = \"{Address}, {ZIPCode}, {City}\".format(Address=address, ZIPCode=zip_code, City=city)\n",
    "    # Get full location details\n",
    "    location = geolocator.geocode(full_address)\n",
    "    # Check if location is empty\n",
    "    if location is not None:\n",
    "        # Get latitude\n",
    "        latitude = location.latitude\n",
    "        # Append latitude\n",
    "        lats.append(latitude)\n",
    "    # If empty, add 0\n",
    "    else:\n",
    "        # Ste lats to 0\n",
    "        latitude = 0\n",
    "        # Append latitude\n",
    "        lats.append(latitude)\n",
    "    # Check if location is empty\n",
    "    if location is not None:\n",
    "        # Get longitude\n",
    "        longitude = location.longitude\n",
    "        # Append longitude\n",
    "        longs.append(longitude)\n",
    "    # If empty, add 0\n",
    "    else:\n",
    "        longitude = 0\n",
    "        # Append finding to df\n",
    "        longs.append(longitude)\n",
    "\n",
    "\n",
    "# Add longs and lats to restaurant df\n",
    "restaurants['LATITUDE'] = lats\n",
    "restaurants['LONGITUDE'] = longs\n",
    "\n",
    "# Visualize\n",
    "restaurants.head()"
   ]
  },
  {
   "source": [
    "As we can see, downloading all information took us ~1 minute. That is not bad. However, Nominatim sometimes cannot find the addresses provided. For these cases, we have added a simple if loop in the code above. Our loop adds \"0\" to latitude and longitude when Nominatim cannot find the address. So let us check how many addresses are affected:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 121/121 [00:00<00:00, 4332.92it/s]Inder Suerst 3\n",
      "Bra Wo-Allee 1\n",
      "Otto-Lillienthal-Strasse 19\n",
      "Speicherstrasse 1\n",
      "Hanauer Landstrasse 110\n",
      "Bleichenbruecke 9\n",
      "Bruesseler Strasse 14\n",
      "Ander Untertrave 111\n",
      "Anden Reeperbahnen 2\n",
      "Enzian Hoefe\n",
      "Duesseldorferstrasse 162\n",
      "Muehlstrasse 17\n",
      "Am Hafendeck 6 - 8\n",
      "Ander Vorburg 1\n",
      "\n",
      "We are missing coordinates for 14 restaurants.\n",
      "That is 11.57% of our dataset.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Start counter\n",
    "counter = 0\n",
    "\n",
    "# Loop through dataset\n",
    "for i in tqdm(range(len(restaurants.index))):\n",
    "    # If 0 in latitude, print street name\n",
    "    if restaurants.iloc[i, 3:4].values[0] == 0:\n",
    "        # Print address\n",
    "        print(restaurants.iloc[i, 0:1].values[0])\n",
    "        # Add 1 to counter\n",
    "        counter += 1\n",
    "    # If large 0\n",
    "    else:\n",
    "        # Do nothing\n",
    "        continue\n",
    "\n",
    "# Spacer\n",
    "print() \n",
    "\n",
    "# Show counter\n",
    "print(\"We are missing coordinates for {counter} restaurants.\".format(counter=counter))\n",
    "\n",
    "# Calculate share of dataset\n",
    "print(\"That is {:.2f}% of our dataset.\".format(counter/121*100))"
   ]
  },
  {
   "source": [
    "We can observe that 14 restaurants have no coordinates. A closer look at the respective addresses shows us that some of them are written wrongly (e.g. \"Ander Vorburg 1\" should be \"An der Vorburg 1\"). We could try to fix these addresses and run our code section again, however, as the amount restaurants with missing coordinates is below 20% of our dataset, we can accept the discrepancies and exclude these restaurants from our analysis instead:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(107, 6)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                     STREET ZIP_CODE      CITY   LATITUDE  LONGITUDE  \\\n",
       "0      Gut-Daemme-Strasse 1    52070    Aachen  50.797335   6.107450   \n",
       "1       Franziskanergasse 5    92224    Amberg  49.446234  11.855468   \n",
       "2  Pearl-S.-Buck-Strasse 12    86156  Augsburg  48.371837  10.865182   \n",
       "3  Albert-Schenavsky-Str. 2    86165  Augsburg  48.381857  10.931547   \n",
       "4      Maximilianstrasse 83    95444  Bayreuth  49.944196  11.571159   \n",
       "\n",
       "  MUNICIPALITY  \n",
       "0         None  \n",
       "1         None  \n",
       "2         None  \n",
       "3         None  \n",
       "4         None  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>STREET</th>\n      <th>ZIP_CODE</th>\n      <th>CITY</th>\n      <th>LATITUDE</th>\n      <th>LONGITUDE</th>\n      <th>MUNICIPALITY</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Gut-Daemme-Strasse 1</td>\n      <td>52070</td>\n      <td>Aachen</td>\n      <td>50.797335</td>\n      <td>6.107450</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Franziskanergasse 5</td>\n      <td>92224</td>\n      <td>Amberg</td>\n      <td>49.446234</td>\n      <td>11.855468</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Pearl-S.-Buck-Strasse 12</td>\n      <td>86156</td>\n      <td>Augsburg</td>\n      <td>48.371837</td>\n      <td>10.865182</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Albert-Schenavsky-Str. 2</td>\n      <td>86165</td>\n      <td>Augsburg</td>\n      <td>48.381857</td>\n      <td>10.931547</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Maximilianstrasse 83</td>\n      <td>95444</td>\n      <td>Bayreuth</td>\n      <td>49.944196</td>\n      <td>11.571159</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "# Get indexed with lat == 0\n",
    "index_names = restaurants[(restaurants['LATITUDE'] == 0 )].index\n",
    "\n",
    "# Kick out entries with lat == 0\n",
    "restaurants.drop(index_names, inplace=True) \n",
    "\n",
    "# Reset index\n",
    "restaurants.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Visualize\n",
    "print(restaurants.shape)\n",
    "restaurants.head()"
   ]
  },
  {
   "source": [
    "Great! Now, we have a data set that we can continue working with. In our next step, we will check which coordinates are lying in which German municipalty. Why are we doing this? Since we do not know the address information for our Facebook data, we need to filter it somehow. Once we know which municipalties are relevant for our L'Osteria restaurants, we can reproduce the steps to assign our Facebook data accordingly.\n",
    "<br>\n",
    "<br>\n",
    "To achieve this, we will use the [turfpy](https://pypi.org/project/turfpy/) library by Omkar Mestry and Sachrin Kharude. The library checks whether a gemoetric point lies within a specified polygon and returns a boolean value. \n",
    "<br>\n",
    "<br>\n",
    "As the library works with geometric object types, we first need to convert our municipality coordinates to the required object types:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Wall time: 4.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Import working libraries\n",
    "from geojson import Point, Polygon, Feature\n",
    "\n",
    "# Create temporary variable\n",
    "copy = copy = municipalities.copy()\n",
    "\n",
    "# Convert coordinates to polygon objects\n",
    "copy['coords'] = copy.apply(lambda row: Polygon([row['coords']]), axis=1)"
   ]
  },
  {
   "source": [
    "We then can use turfpy to match our L'Osteria coordinates against the individual German border polygons. When a match is found, the respective municipality is stored in a new column in our restaurans variable:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Wall time: 2min 28s\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                     STREET ZIP_CODE      CITY   LATITUDE  LONGITUDE  \\\n",
       "0      Gut-Daemme-Strasse 1    52070    Aachen  50.797335   6.107450   \n",
       "1       Franziskanergasse 5    92224    Amberg  49.446234  11.855468   \n",
       "2  Pearl-S.-Buck-Strasse 12    86156  Augsburg  48.371837  10.865182   \n",
       "3  Albert-Schenavsky-Str. 2    86165  Augsburg  48.381857  10.931547   \n",
       "4      Maximilianstrasse 83    95444  Bayreuth  49.944196  11.571159   \n",
       "\n",
       "  MUNICIPALITY  \n",
       "0       Aachen  \n",
       "1       Amberg  \n",
       "2     Augsburg  \n",
       "3     Augsburg  \n",
       "4     Bayreuth  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>STREET</th>\n      <th>ZIP_CODE</th>\n      <th>CITY</th>\n      <th>LATITUDE</th>\n      <th>LONGITUDE</th>\n      <th>MUNICIPALITY</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Gut-Daemme-Strasse 1</td>\n      <td>52070</td>\n      <td>Aachen</td>\n      <td>50.797335</td>\n      <td>6.107450</td>\n      <td>Aachen</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Franziskanergasse 5</td>\n      <td>92224</td>\n      <td>Amberg</td>\n      <td>49.446234</td>\n      <td>11.855468</td>\n      <td>Amberg</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Pearl-S.-Buck-Strasse 12</td>\n      <td>86156</td>\n      <td>Augsburg</td>\n      <td>48.371837</td>\n      <td>10.865182</td>\n      <td>Augsburg</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Albert-Schenavsky-Str. 2</td>\n      <td>86165</td>\n      <td>Augsburg</td>\n      <td>48.381857</td>\n      <td>10.931547</td>\n      <td>Augsburg</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Maximilianstrasse 83</td>\n      <td>95444</td>\n      <td>Bayreuth</td>\n      <td>49.944196</td>\n      <td>11.571159</td>\n      <td>Bayreuth</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 95
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Import working libraries\n",
    "from turfpy.measurement import boolean_point_in_polygon\n",
    "\n",
    "# Define function to find matching municipality polygon\n",
    "def find_municipality(lat, lng):\n",
    "    # Define point \n",
    "    point = Feature(geometry=Point((lat, lng)))\n",
    "    # Check against municipalities\n",
    "    for i in range(len(copy.index)):\n",
    "        # Get municipality\n",
    "        municipality = copy.iloc[i, 0:1].values[0]\n",
    "        # Get polygon\n",
    "        polygon = copy.iloc[i, 2:3].values[0]\n",
    "        # Check if point is in polygon\n",
    "        if boolean_point_in_polygon(point, polygon) == True:\n",
    "            # Store municipality in variable\n",
    "            return municipality\n",
    "            # Return to main loop\n",
    "            break\n",
    "\n",
    "# Execute function\n",
    "restaurants['MUNICIPALITY'] = restaurants.apply(lambda row: find_municipality(lat=row['LATITUDE'], lng=row['LONGITUDE']), axis=1)\n",
    "\n",
    "# Visualize\n",
    "restaurants.head()"
   ]
  },
  {
   "source": [
    "As you can see, this process takes quite some time. We will therefore save the dataset in a CSV file so that we can upload it, if necessary.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "restaurants.to_csv(r'C:\\Users\\maurice.buettgenbach\\OneDrive - Aquila Capital Management GmbH\\Desktop\\Desktop\\Private\\IBM\\10_Capstone project\\IBM_The_battle_of_neighborhoods\\restaurants_data.csv', index = False)"
   ]
  },
  {
   "source": [
    "Let us briefly check whether that worked:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                     STREET  ZIP_CODE      CITY   LATITUDE  LONGITUDE  \\\n",
       "0      Gut-Daemme-Strasse 1     52070    Aachen  50.797335   6.107450   \n",
       "1       Franziskanergasse 5     92224    Amberg  49.446234  11.855468   \n",
       "2  Pearl-S.-Buck-Strasse 12     86156  Augsburg  48.371837  10.865182   \n",
       "3  Albert-Schenavsky-Str. 2     86165  Augsburg  48.381857  10.931547   \n",
       "4      Maximilianstrasse 83     95444  Bayreuth  49.944196  11.571159   \n",
       "\n",
       "  MUNICIPALITY  \n",
       "0       Aachen  \n",
       "1       Amberg  \n",
       "2     Augsburg  \n",
       "3     Augsburg  \n",
       "4     Bayreuth  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>STREET</th>\n      <th>ZIP_CODE</th>\n      <th>CITY</th>\n      <th>LATITUDE</th>\n      <th>LONGITUDE</th>\n      <th>MUNICIPALITY</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Gut-Daemme-Strasse 1</td>\n      <td>52070</td>\n      <td>Aachen</td>\n      <td>50.797335</td>\n      <td>6.107450</td>\n      <td>Aachen</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Franziskanergasse 5</td>\n      <td>92224</td>\n      <td>Amberg</td>\n      <td>49.446234</td>\n      <td>11.855468</td>\n      <td>Amberg</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Pearl-S.-Buck-Strasse 12</td>\n      <td>86156</td>\n      <td>Augsburg</td>\n      <td>48.371837</td>\n      <td>10.865182</td>\n      <td>Augsburg</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Albert-Schenavsky-Str. 2</td>\n      <td>86165</td>\n      <td>Augsburg</td>\n      <td>48.381857</td>\n      <td>10.931547</td>\n      <td>Augsburg</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Maximilianstrasse 83</td>\n      <td>95444</td>\n      <td>Bayreuth</td>\n      <td>49.944196</td>\n      <td>11.571159</td>\n      <td>Bayreuth</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 71
    }
   ],
   "source": [
    "# Load CSV\n",
    "restaurants = pd.read_csv('restaurants_data.csv')\n",
    "\n",
    "# Visualize\n",
    "restaurants.head()"
   ]
  },
  {
   "source": [
    "Alright - this hopefully will save us some time! In the next step, we have to reproduce the above step and match our facebook data with the German border data. In result, we will be able to filter our Facebook data more conveniently and also add some more geospatial information.\n",
    "<br>\n",
    "<br>\n",
    "However, if you decide to run this code yourself, be aware that this operation takes pretty long as well. It is sinificantly faster than reverse engineering all coordinates in the Facebook dataset but still takes ~1 day to run. So you might as well do somethin else why the computer does its job! The data will also be saved in a CSV file so that we do not need to perform this step everytime we re-run this notebook."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 3/3 [00:55<00:00, 18.41s/it]\n"
     ]
    }
   ],
   "source": [
    "# Create copy from populations variable\n",
    "copy = population.copy()\n",
    "\n",
    "# Create temporary variable to store found municipality\n",
    "found_municipality = []\n",
    "\n",
    "# Loop through copy to check for municipalties\n",
    "for i in tqdm(range(len(copy[:3].index))):\n",
    "    # Define point \n",
    "    point = Feature(geometry=Point((copy.iloc[i, 0:1].values[0], copy.iloc[i, 1:2].values[0])))\n",
    "    # Loop through polygons and check whether point lies in them\n",
    "    for x in range(len(municipalities.index)):\n",
    "        # Get municipality\n",
    "        municipality = municipalities.iloc[x, 0:1].values[0]\n",
    "        # Get polygon\n",
    "        polygon = Polygon([municipalities.iloc[x, 2:3].values[0]])\n",
    "        # Check if point is in polygon\n",
    "        if boolean_point_in_polygon(point, polygon) == True:\n",
    "            # Store found municipality in variable\n",
    "            found_municipality.append(municipality)\n",
    "            # Return to main loop\n",
    "            break\n",
    "\n",
    "# Store municipality in restaurants variable\n",
    "# population['MUNICIPALITY'] = found_municipality\n",
    "\n",
    "# # Spacer\n",
    "# print()\n",
    "# print()\n",
    "\n",
    "# # Visualize\n",
    "# restaurants.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Bad Herrenalb', 'Bad Herrenalb', 'Bad Herrenalb']"
      ]
     },
     "metadata": {},
     "execution_count": 74
    }
   ],
   "source": [
    "found_municipality"
   ]
  },
  {
   "source": [
    "## THE LIBRARIES <a name=\"THE_LIBRARIES\" ></a>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Libraries imported.\n"
     ]
    }
   ],
   "source": [
    "# Data wrangling\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# URL handling\n",
    "from urllib.request import urlopen\n",
    "import json\n",
    "\n",
    "# Web scraping\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Geo data\n",
    "from turfpy.measurement import boolean_point_in_polygon\n",
    "from geojson import Point, Polygon, Feature\n",
    "\n",
    "# Visualization\n",
    "from folium import plugins\n",
    "from folium.plugins import HeatMap\n",
    "import plotly.express as px\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Check out\n",
    "print('Libraries imported.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# point = Feature(geometry=Point((-46.6318, -23.5523)))\n",
    "# polygon = Polygon(\n",
    "#     [\n",
    "#         [\n",
    "#             (-46.653, -23.543),\n",
    "#             (-46.634, -23.5346),\n",
    "#             (-46.613, -23.543),\n",
    "#             (-46.614, -23.559),\n",
    "#             (-46.631, -23.567),\n",
    "#             (-46.653, -23.560),\n",
    "#             (-46.653, -23.543),\n",
    "#         ]\n",
    "#     ]\n",
    "# )\n",
    "# boolean_point_in_polygon(point, polygon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 1000/1000 [08:19<00:00,  2.00it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create temporary variable\n",
    "df = population.head(1000)\n",
    "\n",
    "# Create empty list \n",
    "addresses = []\n",
    "\n",
    "# Create counter\n",
    "counter = 0\n",
    "\n",
    "# Set geolocator\n",
    "geolocator = Nominatim(user_agent=\"german_italian_restaurant\")\n",
    "\n",
    "# Loop through df and get addresses for coordinates\n",
    "for i in tqdm(range(len(df))):\n",
    "    # Extract coordinates\n",
    "    lat = str(df.iloc[i, 0:1].to_numpy()[0])\n",
    "    lng = str(df.iloc[i, 1:2].to_numpy()[0])\n",
    "    # Create string from coordinates\n",
    "    coordinates = str(lat + \", \" + lng)\n",
    "    # Get location with geopy\n",
    "    location = geolocator.reverse(coordinates)\n",
    "    # Store in variable\n",
    "    addresses.append(location.address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 25/25 [00:00<00:00, 464.47it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create address data\n",
    "address_data = pd.DataFrame()\n",
    "\n",
    "# Loop through addresses and append them to adress df\n",
    "for i in tqdm(range(len(addresses))):\n",
    "    # Split strings\n",
    "    temp = addresses[i].split(\",\")\n",
    "    # Convert to df\n",
    "    df = pd.DataFrame(temp)\n",
    "    # Transpose\n",
    "    df = pd.DataFrame.transpose(df)\n",
    "    # Concatenate\n",
    "    frames = [df, address_data]\n",
    "    address_data = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 44%|████▍     | 11/25 [00:00<00:00, 89.18it/s]\n"
     ]
    }
   ],
   "source": [
    "# Loop through address df and check for inconsistency\n",
    "for column in tqdm(address_data):\n",
    "    # Check for NaN values\n",
    "    if address_data[column].isnull().values.any():\n",
    "        # If NaN detected, check each row\n",
    "        for i in range(len(address_data)):\n",
    "            # Check for NaN in cell\n",
    "            if pd.isna(address_data.iloc[i, column]) == True:\n",
    "                # If NaN in cell, shift row\n",
    "                address_data.iloc[i] = address_data.iloc[i].shift(1)\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(25, 11)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    0                    1                    2   \\\n",
       "0  NaN                  NaN                  NaN   \n",
       "0  NaN  Trampolin oder Pool   Moosbronner Straße   \n",
       "0  NaN                  145        Gaistalstraße   \n",
       "0  NaN                   21       Im Wiesengrund   \n",
       "0  NaN                  NaN                   28   \n",
       "\n",
       "                                  3           4               5   \\\n",
       "0  Bienenzüchterverein Bad Herrenalb   Herrenalb   Bad Herrenalb   \n",
       "0                             Althof    Bernbach   Bad Herrenalb   \n",
       "0                    Unteres Gaistal   Herrenalb   Bad Herrenalb   \n",
       "0                    Unteres Gaistal   Herrenalb   Bad Herrenalb   \n",
       "0                    Wallfahrtstraße     Neusatz   Bad Herrenalb   \n",
       "\n",
       "                                       6                7   \\\n",
       "0   Verwaltungsgemeinschaft Bad Herrenalb   Landkreis Calw   \n",
       "0   Verwaltungsgemeinschaft Bad Herrenalb   Landkreis Calw   \n",
       "0   Verwaltungsgemeinschaft Bad Herrenalb   Landkreis Calw   \n",
       "0   Verwaltungsgemeinschaft Bad Herrenalb   Landkreis Calw   \n",
       "0   Verwaltungsgemeinschaft Bad Herrenalb   Landkreis Calw   \n",
       "\n",
       "                   8       9             10  \n",
       "0   Baden-Württemberg   76332   Deutschland  \n",
       "0   Baden-Württemberg   76332   Deutschland  \n",
       "0   Baden-Württemberg   76332   Deutschland  \n",
       "0   Baden-Württemberg   76332   Deutschland  \n",
       "0   Baden-Württemberg   76332   Deutschland  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Bienenzüchterverein Bad Herrenalb</td>\n      <td>Herrenalb</td>\n      <td>Bad Herrenalb</td>\n      <td>Verwaltungsgemeinschaft Bad Herrenalb</td>\n      <td>Landkreis Calw</td>\n      <td>Baden-Württemberg</td>\n      <td>76332</td>\n      <td>Deutschland</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>NaN</td>\n      <td>Trampolin oder Pool</td>\n      <td>Moosbronner Straße</td>\n      <td>Althof</td>\n      <td>Bernbach</td>\n      <td>Bad Herrenalb</td>\n      <td>Verwaltungsgemeinschaft Bad Herrenalb</td>\n      <td>Landkreis Calw</td>\n      <td>Baden-Württemberg</td>\n      <td>76332</td>\n      <td>Deutschland</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>NaN</td>\n      <td>145</td>\n      <td>Gaistalstraße</td>\n      <td>Unteres Gaistal</td>\n      <td>Herrenalb</td>\n      <td>Bad Herrenalb</td>\n      <td>Verwaltungsgemeinschaft Bad Herrenalb</td>\n      <td>Landkreis Calw</td>\n      <td>Baden-Württemberg</td>\n      <td>76332</td>\n      <td>Deutschland</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>NaN</td>\n      <td>21</td>\n      <td>Im Wiesengrund</td>\n      <td>Unteres Gaistal</td>\n      <td>Herrenalb</td>\n      <td>Bad Herrenalb</td>\n      <td>Verwaltungsgemeinschaft Bad Herrenalb</td>\n      <td>Landkreis Calw</td>\n      <td>Baden-Württemberg</td>\n      <td>76332</td>\n      <td>Deutschland</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>28</td>\n      <td>Wallfahrtstraße</td>\n      <td>Neusatz</td>\n      <td>Bad Herrenalb</td>\n      <td>Verwaltungsgemeinschaft Bad Herrenalb</td>\n      <td>Landkreis Calw</td>\n      <td>Baden-Württemberg</td>\n      <td>76332</td>\n      <td>Deutschland</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 137
    }
   ],
   "source": [
    "print(address_data.shape)\n",
    "address_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set column names\n",
    "columns = [\n",
    "    'STREET_NUMBER',\n",
    "    'STREET',\n",
    "    'NEIGHBORHOOD',\n",
    "    'CITY'\n",
    "    ]"
   ]
  }
 ]
}