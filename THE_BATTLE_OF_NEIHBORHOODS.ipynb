{
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# TABLE OF CONTENT\r\n",
                "+ THE BUSINESS CASE\r\n",
                "+ THE DATA\r\n",
                "+ THE METHODOLOGY"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# THE BUSINESS PROBLEM\r\n",
                "According to [Wikipedia](https://en.wikipedia.org/wiki/Types_of_restaurants), you can classify restaurants into seven categories that in turn can be broken down into eleven variations. Some of these combinations might be a little odd (e.g. \"Fine Dining\" and \"Pub\") but let us assume for a minute that this list is complete and all combinations are possible. In result, we would have 77 unique combinations of how a restaurant could look like. [Wikipedia](https://en.wikipedia.org/wiki/List_of_cuisines) also hosts a list of cuisines and cuisine types. According to Wikipedia, there are five major cusine styles and 123 distinguished ethnic and religious cuisines, giving us 615  combinations for different types of food that we could eat. If we trust these figures, we are all in all looking at a possible variety of over 43,000 unique restaurants - great, right?\r\n",
                "<br>\r\n",
                "<br>\r\n",
                "![But why](https://media.giphy.com/media/s239QJIh56sRW/giphy.gif)\r\n",
                "<br>\r\n",
                "<br>\r\n",
                "Glad you asked! These figures do not really matter for our problem. I only wanted to show you one thing: The food industry is extremely diverse and each type of restaurant brings its own unique challenges. However, they all have one common issue: Location, location, location! No matter what type of restaurant you own, you need a specific location that matches your profile. Of course you could now say: \"That's easy to fix - just go where a lot of people are!\" \r\n",
                "<br>\r\n",
                "<br>\r\n",
                "But is it really so easy? Depending on your restaurant, you need parking space. Maybe you want a quite neighborhood because you own a fine dining restaurant. Maybe you don't want to be where a lot of other restaurants are that are similiar to the cuisine you offer. Or maybe you have a super trendy concept that requires your restaurant to be placed in the most hipster district of your city. We could make this list longer and longer but the point is: It ain't easy. \r\n",
                "<br>\r\n",
                "<br>\r\n",
                "Choosing the right location also becomes increasingly difficult when you don't know the city you want to open your restaurant in. Finding the right spot will require you to do some extensive research and location scouting. This process takes a lot of time and eats up ressources. While this approach is feasible for small businesses, it becomes unhandy for larger corporations who want to expand their restaurants to multiple cities at the same time. In result, corporations need to spend more money to keep up quality and speed. So how could we help larger restaurant corporations to make this process more efficient? \r\n",
                "<br>\r\n",
                "<br>\r\n",
                "Well, with data science of course! Larger restaurant chains usually already have a couple of restaurants in place and know which locations run well in their business model and which not. We can use this information to train a clustering algorithm to identify neighborhoods that are similar to the locations with profitable restaurants. This way we can build a recommender system that tells us which neighborhoods in a new town are more likely to host a successful restaurant. Consequently, we would not have to research all areas but could focus our scouting activity on the most promising neighborhoods. This way, we would be able to improve speed and quality as well as cut the related costs significantly."
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "<br>\r\n",
                "<br>"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# THE DATA"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## L'OSTERIA\r\n",
                "As our business problem aims to build a recommender system for a fast growing restaurant chain, we need an example that we can work with. Ladies and gentlemen, please welcome my favorite pizza chain: [L'Osteria](https://losteria.net/en/)!\r\n",
                "<br>\r\n",
                "<br>\r\n",
                "L'Osteria is an italian restaurant chain that was founded in Germany in 1999. The first restaurant was quickly becomming a hit as it combined tasty food, a trendy atmosphere and reasonable prices. Today, the chain has expanded to basically every larger city in Germany and starts to go international with places in Switzerland, Austria, Netherlands and the UK.\r\n",
                "<br>\r\n",
                "<br>\r\n",
                "The chain has a major focus on Germany and it basically has one (or even multiple) restaurants in every bigger city in Germany. That gives us a lot of possibilities to train our algorithm. Unfortunately, we do not have access to L'Osteria's database which is why we need to construct our own workaround. Luckily for us, the chain publishes the addresses of all their restaurants on their [website](https://losteria.net/en/restaurants/view/list/?tx_losteriarestaurants_restaurantsreopening%5Bfilter%5D%5Bcountry%5D=de&tx_losteriarestaurants_restaurantsreopening%5Bfilter%5D%5BsearchTerm%5D=&&&tx_losteriarestaurants_restaurantsreopening%5Bfilter%5D%5Btype%5D=reservations&).\r\n",
                "<br>\r\n",
                "<br>\r\n",
                "To use this information, we need to scrape it from their website. When you take a closer look at the L'Osteria website, you will notice that it uses an event button which hides most of the restaurants. We could use a library called [Selenium](https://www.selenium.dev/), if we want a fully automized script that clicks the button for us. However, that would be an overkill as the button only needs to be clicked ~10 times. In result, it is easier to do so by hand and download the website that now shows all restaurants and store it as a html file in our working directory. \r\n",
                "<br>\r\n",
                "<br>\r\n",
                "That enables us to use the infamous html scraping library [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/). The following code scrapes the data we need from the downloaded html file (also available in the repository) and transforms it as the file contains e.g German characters that otherwise result in jibberish. "
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "source": [
                "# Import working libraries\r\n",
                "import pandas as pd # Data wrangling\r\n",
                "from tqdm import tqdm # Progress visualization\r\n",
                "import requests # Request handling\r\n",
                "from bs4 import BeautifulSoup # HTML search\r\n",
                "import re # String handling\r\n",
                "import ast # String handling\r\n",
                "\r\n",
                "# Set path to html file\r\n",
                "path = r\"C:\\Users\\maurice.buettgenbach\\OneDrive - Aquila Capital Management GmbH\\Desktop\\Desktop\\Private\\IBM\\10_Capstone project\\IBM_The_battle_of_neighborhoods_v2\\LOSTERIA_DATA\\Restaurants - L'Osteria.htm\"\r\n",
                "\r\n",
                "# Open document and transform to BS object\r\n",
                "with open(path) as page:\r\n",
                "    soup = BeautifulSoup(page, 'html.parser')\r\n",
                "\r\n",
                "# Define results\r\n",
                "results = soup.find(id='losteria-restaurants-list-wrapper')\r\n",
                "\r\n",
                "# Find elements\r\n",
                "page_elements = results.find_all('div', class_='address')\r\n",
                "\r\n",
                "# Create variable to store data in\r\n",
                "restaurants = pd.DataFrame()\r\n",
                "\r\n",
                "# Iterate through found elements\r\n",
                "for page_element in tqdm(page_elements):\r\n",
                "    # Isolate address\r\n",
                "    element = str(page_element)\r\n",
                "    # Get rid of unnecessary characters\r\n",
                "    element = element.replace(\"\\n\", \"\")\r\n",
                "    element = element.replace(\"\\r\", \"\")\r\n",
                "    # Get rid of spaces\r\n",
                "    element = element.replace(\" \", \"\")\r\n",
                "    # Search for address in between <div>\r\n",
                "    search_result = re.search(\">(.*)<\", element)\r\n",
                "    # Store search result in new variable\r\n",
                "    address = search_result.group(1)\r\n",
                "    # Get street\r\n",
                "    street = address.split(\",\")[0]\r\n",
                "    # Add space between street name and house number\r\n",
                "    street = re.sub(r\"([0-9]+(\\.[0-9]+)?)\",r\" \\1 \", street).strip()\r\n",
                "    # Add space before Capital letter\r\n",
                "    street = re.sub(r\"(?<=\\w)([A-Z])\", r\" \\1\", street).strip()\r\n",
                "    # Get ZIP code and city\r\n",
                "    address = address.split(\",\")[1]\r\n",
                "    # Isolate ZIP code\r\n",
                "    zip_code = re.split('(\\d+)', address)[1]\r\n",
                "    # Isolate city\r\n",
                "    city = re.split('(\\d+)', address)[2]\r\n",
                "    # Create temporary df\r\n",
                "    temp_df = pd.DataFrame()\r\n",
                "    # Add data to df\r\n",
                "    temp_df['STREET'] = [street]\r\n",
                "    temp_df['ZIP_CODE'] = zip_code\r\n",
                "    temp_df['CITY'] = city\r\n",
                "    # Append to variable\r\n",
                "    restaurants = restaurants.append(temp_df)\r\n",
                "# Reset index\r\n",
                "restaurants.reset_index(drop=True, inplace=True)\r\n",
                "\r\n",
                "# Replace cryptic html for German characters\r\n",
                "restaurants = restaurants.replace('Ã¤', \"ae\", regex=True) # For German Umlaut \"ä\"\r\n",
                "restaurants = restaurants.replace('Ã¼', \"ue\", regex=True) # For German Umlaut \"ü\"\r\n",
                "restaurants = restaurants.replace('Ã¶', \"oe\", regex=True) # For German Umlaut \"ö\"\r\n",
                "restaurants = restaurants.replace('ÃŸ', \"ss\", regex=True) # For German Umlaut \"ß\"\r\n",
                "\r\n",
                "# Add spacer for output\r\n",
                "print()\r\n",
                "print()\r\n",
                "\r\n",
                "# Visualize variable\r\n",
                "print(\"df shape:\", restaurants.shape)\r\n",
                "restaurants.head(10)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "100%|██████████| 121/121 [00:00<00:00, 438.69it/s]\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "\n",
                        "\n",
                        "df shape: (121, 3)\n"
                    ]
                },
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "                     STREET ZIP_CODE      CITY\n",
                            "0      Gut-Daemme-Strasse 1    52070    Aachen\n",
                            "1       Franziskanergasse 5    92224    Amberg\n",
                            "2  Pearl-S.-Buck-Strasse 12    86156  Augsburg\n",
                            "3  Albert-Schenavsky-Str. 2    86165  Augsburg\n",
                            "4      Maximilianstrasse 83    95444  Bayreuth\n",
                            "5     Hilda-Geiringer-Weg 4    10557    Berlin\n",
                            "6          Alt Mahlsdorf 88    12623    Berlin\n",
                            "7          Memhardstrasse 3    10178    Berlin\n",
                            "8   Mildred-Harnack-Str. 11    10243    Berlin\n",
                            "9            Savignyplatz 5    10623    Berlin"
                        ],
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>STREET</th>\n",
                            "      <th>ZIP_CODE</th>\n",
                            "      <th>CITY</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>Gut-Daemme-Strasse 1</td>\n",
                            "      <td>52070</td>\n",
                            "      <td>Aachen</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>Franziskanergasse 5</td>\n",
                            "      <td>92224</td>\n",
                            "      <td>Amberg</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>Pearl-S.-Buck-Strasse 12</td>\n",
                            "      <td>86156</td>\n",
                            "      <td>Augsburg</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>Albert-Schenavsky-Str. 2</td>\n",
                            "      <td>86165</td>\n",
                            "      <td>Augsburg</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>Maximilianstrasse 83</td>\n",
                            "      <td>95444</td>\n",
                            "      <td>Bayreuth</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>5</th>\n",
                            "      <td>Hilda-Geiringer-Weg 4</td>\n",
                            "      <td>10557</td>\n",
                            "      <td>Berlin</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>6</th>\n",
                            "      <td>Alt Mahlsdorf 88</td>\n",
                            "      <td>12623</td>\n",
                            "      <td>Berlin</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>7</th>\n",
                            "      <td>Memhardstrasse 3</td>\n",
                            "      <td>10178</td>\n",
                            "      <td>Berlin</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>8</th>\n",
                            "      <td>Mildred-Harnack-Str. 11</td>\n",
                            "      <td>10243</td>\n",
                            "      <td>Berlin</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>9</th>\n",
                            "      <td>Savignyplatz 5</td>\n",
                            "      <td>10623</td>\n",
                            "      <td>Berlin</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 4
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## UBER H3 \r\n",
                "I was lucky enough to travel a lot in my youth but it is still impossible for me to tell whether a restaurant is located in a trendy neighborhood or not. To draw any conclusions on the neighborhoods the restaurants are located in, I would have to google their locations and research the respective city as a whole. However, L'Osteria has over 100 restaurants in Europe - it would therefore take me days or even weeks to conduct a respective analysis. \r\n",
                "<br>\r\n",
                "<br>\r\n",
                "Since this is anything else but ressource efficient, we have to find a way of speeding things up. In order to analyse the location of each restaurant, we need to define a radius from which we want to draw conclusions from. One approach would be to get shapefiles for each neighborhood in each city L'Osteria has a restaurant in and then download information related to these neigborhoods. But good luck trying to get these shapefile for Germany. Here, every state has its own data service - one more confusing than the other. Collecting the necessary data would take weeks and provide us with a minimal granularity.\r\n",
                "<br>\r\n",
                "<br>\r\n",
                "This is where Uber's H3 hexagonial mapping framework comes in play. At its core, H3 is a geospatial analysis tool that provides a global index of hirachically ordered hexagons. Just imagine that you would map the entire earth (pole to pole) in hexagonial polygons. Now, each hexagon would receive a unique ID so that you could exactly tell what place on earth belongs to which hexagon. And finally, think of different layers of hexagons. Each layer is much smaller and more precise, enabling you to drill up and down on your map. That is exactly what H3 does - it provides you unique hexagons with different resolutions, all the way down to a precision of 0.0000009 km² area. \r\n",
                "<br>\r\n",
                "<br>\r\n",
                "So how is this helping us? By knowing the GPS coordinates of the L'Osteria restaurants, we can assign them to an unique hexagon. This hexagon will then serve as our designated radius for which we will download further data for our analysis. The H3 framework also helps us to map any city on earth with the same size of hexagons, making it easier for us to compare our results. "
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## OPEN STREET MAP\r\n",
                "We can analyze the area of our L'Osteria locations by downloading the information linked to the neighbouring hexagons by defining the degree of neighbours we want to take into account. If we analyze all first degree neighbours, we would analyze the information of the six hexagons that are directly linked to the hexagon a restaurant is located in. And if we would analyze the second degree neighbours, we would analyze all hexagons that are linked to the first degree neighbours as well. \r\n",
                "<br>\r\n",
                "<br>\r\n",
                "However, if we want to analyze a specific area such as a city, we cannot use this approach since we are limited to borders that are not considered under H3. The closer we get to the borders of a city, the more hexagons we would observe that are located outside of the city's borders. Hence, our data could be distorted. So what do we do?\r\n",
                "<br>\r\n",
                "<br>\r\n",
                "We need shape files. A shape file is a specific data format that allows you to handle geospatial data. In our case, we are specifically interested in shapefiles that contain border information of European cities. There are many data providers that offer this information in form of a shape file. Since we are on a budget, we will use the shape files provided by [OpenStreetMap](https://www.openstreetmap.de/). OpenStreetMap is an international project founded in 2004 with the goal of creating a free map of the world. For this purpose they collect data about roads, railroads, rivers, forests, houses and much more worldwide. However, the shapefiles we are interested in are provided by [Geofabrik](https://www.geofabrik.de/) which is a German provider who built its service based on OpenStreetMap. Here, you can download shapefiles of various countries, regions and cities for free."
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## FOURSQUARE\r\n",
                "[Foursquare](https://foursquare.com/) is an app that lets its users rank all different kinds of venues all over the world. By doing so, Foursquare has build one of the most comprehensive geospatial data sets in the world. The data set covers an extremely large amount of venue and user data that allows you to access everything from a venue's name, location or menu up to user ratings, comments or pictures of each venue. And the best part: Foursquare provides developers an [API](https://developer.foursquare.com/) that is (in limits) free to use! \r\n",
                "<br>\r\n",
                "<br>\r\n",
                "Even though Foursquare provides an incredible variety of data, we will use the venue categories (e.g. sushi restaurant, park, sports club, italian restaurant, etc.) for our analysis only. While it would most likely increase the success of our algorithm to include more information such as rankings or types of user data, we will not include this data due to ressource limitations.\r\n",
                "<br>\r\n",
                "<br>\r\n",
                "We will use the Foursquare data to analyze the area of the hexagons (or neighbouring hexagons) in which L'Osteria has existing restaurants as well as the hexagons of the new city we are interested in. This way we will be able to cluster the hexagons according to their characteristics.\r\n",
                "<br>\r\n",
                "<br>"
            ],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.9.0",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.9.0 64-bit"
        },
        "interpreter": {
            "hash": "119bfaff21b32781f6d2764777c04d49502b53816ae403fe48dcf9da50cdb242"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}